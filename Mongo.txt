- Mongo

-- Recap
- Mongod is the main daemn process for MongoDB
- Default configurations for Mongod
- We use database clients to connect to Mongod

- dbpath
mongod --dbpath <directory path>

- port
mongod --port <port number>

- auth
mongod --auth

- bind_ip
mongod --bind_ip 123.123.123.123

- Launch mongod with specified --dbpath and --logpath:
mongod --dbpath /data/db --logpath /data/log/mongod.log

- Launch mongod and fork the process:
mongod --dbpath /data/db --logpath /data/log/mongod.log --fork


-- Recap
- Configuration File Options
-- Provide the same functionality as command line options.
-- Improve readability of configuration settings.
-- Use the documentation to facilitating mapping.


- Launch mongod with many configuration options:
mongod --dbpath /data/db --logpath /data/log/mongod.log --fork --replSet "M103" --keyFile /data/keyfile --bind_ip "127.0.0.1,192.168.103.100" --tlsMode requireTLS --tlsCAFile "/etc/tls/TLSCA.pem" --tlsCertificateKeyFile "/etc/tls/tls.pem"

- Apply mongod.config
mongod --config "/etc/mongod.conf"
mongod -f  "/etc/mongod.conf"

-- mongod.config
storage:
  dbPath: "/data/db"
systemLog:
  destination: file
  path: "/root/workspace/logs"
net:
  port : 27000
security:
  authorization : enabled

- apply config
mongod --config mongod.conf

-- create user
mongo admin --host localhost:27000 --eval '
  db.createUser({
    user: "m103-admin",
    pwd: "m103-pass",
    roles: [
      {role: "root", db: "admin"}
    ]
  })
'

-- Recap
- disgnoostic.data and log files assist support in diagnoostics
- do not modify files or folder in the mongodb data directory
- defer to mongodb suppoort or documentation fr instructions on interacting with these files.

-- Basic Helper Groups
- db.<method>.()
-- db.<collection>.<method>.()

--- User Management
---- db.createUser()
---- db.dropUser()

--- Collection Management
----- db.renameCollection()
----- db.collection.createIndex()
----- db.collection.drop()

--- Database Management
----- db.dropDatabase()
----- db.createCollection()

--- Database Status
----- db.serverStatus()

--- Database Commands
----- db.runCommand()
----- db.commandHelp()

- rs.<metrod>.()
- sh.<method>.()

-- Recap
- Database Commands provide foundation for interacting with MongoDB.
- User db.runCommand() to run a database command.
- Mongo Shell provides helper methods to simplify interaction
- Stick to the helper methods for this course.

- Logging Basics
-- Log Verbosity Levels
--- -1: Inherit from parent
--- 0: Default Verbosity, to include informational messages
--- 1 - 5: increases the verbosity level to include Debug messages.

- Log Message Severity
-- F: Fatal
-- E: Error
-- W: Warning
-- I: Information (Verbosity Level 0)
-- D: Debug (Verbosity Level 1-5)

-- Recap
- MongoDB process log supports multiple components for controlling granularity of events captured
- You can retrieve the log from the mongo shell, or using command line utilities like tail.
- You can change the verbosity of any log component from the mongo shell

- Get the logging components:
mongo admin --host 192.168.103.100:27000 -u m103-admin -p m103-pass --eval '
  db.getLogComponents()
'

- Change the logging level:
mongo admin --host 192.168.103.100:27000 -u m103-admin -p m103-pass --eval '
  db.setLogLevel(0, "index")
'

- View the logs through the Mongo shell:
db.adminCommand({ "getLog": "global" })

- View the logs through the command line:
tail -f /data/db/mongod.log

- Look for instructions in the log file with grep:
grep -i 'update' /data/db/mongod.log

- Access log
Running db.adminCommand({ "getLog": "global" }) from the Mongo shell
Running tail -f <path-to-log-file> from the command line

-- Profiling the Database
- The database profiler collects detailed information about Database Commands executed against a running mongod instance. 

db.getProfilingLevel()
db.setProfilingLevel(1)
db.setProfilingLevel(1, { slowms: 0})
db.system.profile.find().pretty()

- To list all of the collection names you can run this command:
db.runCommand({listCollections: 1})

- Get profiling level:
mongo newDB --host 192.168.103.100:27000 -u m103-admin -p m103-pass --authenticationDatabase admin --eval '
  db.getProfilingLevel()
'

- Set profiling level:
mongo newDB --host 192.168.103.100:27000 -u m103-admin -p m103-pass --authenticationDatabase admin --eval '
  db.setProfilingLevel(1)
'

- Show collections:
mongo newDB --host 192.168.103.100:27000 -u m103-admin -p m103-pass --authenticationDatabase admin --eval '
  db.getCollectionNames()
'

- Note: show collections only works from within the shell
Set slowms to 0:
mongo newDB --host 192.168.103.100:27000 -u m103-admin -p m103-pass --authenticationDatabase admin --eval '
  db.setProfilingLevel( 1, { slowms: 0 } )
'

- Insert one document into a new collection:
mongo newDB --host 192.168.103.100:27000 -u m103-admin -p m103-pass --authenticationDatabase admin --eval '
  db.new_collection.insert( { "a": 1 } )
'

- Get profiling data from system.profile:
mongo newDB --host 192.168.103.100:27000 -u m103-admin -p m103-pass --authenticationDatabase admin --eval '
  db.system.profile.find().pretty()
'


-- Recap
- The difference between log data and profile data
- How to configure the profiler
- How to interpret output from the profiler.

-- Problem
- Which of the following events are captured by the profiler?
CRUD operations
Administrative operations
Configuration operations

-- mongod.conf with log and fork configured

storage:
  dbPath: /var/mongodb/db
net:
  bindIp: localhost
  port: 27000
security:
  authorization: enabled
systemLog:
   destination: file
   path: "/var/mongodb/logs/mongod.log"
   logAppend: true
processManagement:
   fork: true   

- Authentication Mechanism
-- Community and Enterprise
---- SCRAM (Basic mechanism)
---- X.509
-- MongoDB Enterprise 
---- LDAP
---- Kerberos
  
- authorization: role based access controll
-- Each user has one or more roles
-- Each Roles has one or more privileges
-- A privilege represents a groups of actions and the resources those actions apply to.

- Create new user with the root role (also, named root):
use admin
db.createUser({
  user: "root",
  pwd: "root123",
  roles : [ "root" ]
})

- Connect to mongod and authenticate as root:
mongo --host 127.0.0.1:27000 --username root --password root123 --authenticationDatabase admin

- Run DB stats:
db.stats()

- Shutdown the server:
use admin
db.shutdownServer()

-- Roles in MongoDB
- Authenticate as root user:
mongo admin -u root -p root123

-Create security officer:
db.createUser(
  { user: "security_officer",
    pwd: "h3ll0th3r3",
    roles: [ { db: "admin", role: "userAdmin" } ]
  }
)

- Create database administrator:
db.createUser(
  { user: "dba",
    pwd: "c1lynd3rs",
    roles: [ { db: "admin", role: "dbAdmin" } ]
  }
)

- Grant role to user:
db.grantRolesToUser( "dba",  [ { db: "playground", role: "dbOwner"  } ] )

- Show role privileges:
db.runCommand( { rolesInfo: { role: "dbOwner", db: "playground" }, showPrivileges: true} )

- dbOwner
The database owner can perform any administratiive action on the database.
This role combines the privileges granted by the readWrite, dbAdmin and userAdmin roles.

-- Recap
- How roles are defined:
  - privileges
  - resources
  - actioons
- List of built-in roles
- How to create users using a built-in
- roles


mongo --host 127.0.0.1:27000 --username m103-admin --password m103-pass

db.createUser(
  { user: "m103-application-user",
    pwd: "m103-application-pass",
    roles: [ { db: "applicationData", role: "readWrite" } ]
  }
)

mongo applicationData --host 127.0.0.1:27000 --username m103-application-user --password m103-application-pass

-- Server Tools Overview
find /user/bin/ -name "mongo*"

- mongostat --port 27017
 insert query update delete getmore command dirty  used flushes vsize   res qrw arw net_in net_out conn                time
    *0    *0     *0     *0       0     2|0  0.2% 80.0%       0 2.62G 2.19G 0|0 4|0   160b   48.4k    4 May 21 17:24:56.581
    *0    42      5     *0       0     1|0  0.2% 79.9%       0 2.62G 2.19G 0|0 4|0  18.6k   60.4k    4 May 21 17:24:57.581

- Use mongodump to get a BSON dump of a MongoDB collection:
mongodump --help
mongodump --port 30000 --db applicationData --collection products
ls dump/applicationData/
cat dump/applicationData/products.metadata.json

- Use mongorestore to restore a MongoDB collection from a BSON dump:
mongorestore --drop --port 30000 dump/

- Use mongoexport to export a MongoDB collection to JSON or CSV (or stdout!):
mongoexport --help
mongoexport --port 30000 --db applicationData --collection products
mongoexport --port 30000 --db applicationData --collection products -o products.json

- Use mongoimport to create a MongoDB collection from a JSON or CSV file:
mongoimport --port 30000 products.json

mongoimport --host 127.0.0.1:27000 --username m103-application-user --password m103-application-pass /dataset/products.json

mongoimport --host 127.0.0.1:27000 --username=m103-application-user --password=m103-application-pass --authenticationDatabase=admin --db=applicationData --collection=products  --file=/dataset/products.json

MongoDB Replica Set
-- Recap
Replica Sets are groups of mongodb
High Availability and Failover
Members can have different roles and specific purpses.

- Setting Up a Replica Set

-- Create the configuration each other
-- Create keyfile authenticate
openssl rand -base64 741 > /var/mongodb/pki/m103-keyfile
chmod 400 /var/mongodb/pki/m103-keyfile
-- add the replication configuration in node1.conf
-- create folder to node1
-- start node1
mongod -f node1.conf
-- cp node1.conf node2.conf
-- change the reference from node1 to node2
-- cp node1.conf node3.conf
-- change the reference from node1 to node3
-- connect in mongo 
mongo --port 27011
-- execute: rs.initiate()
-- create user to connect with root role and admin db.
use admin
db.createUser...
-- connect to replicaset with the new user, add the name f replicaset in the hostname
-- execute
rs.status()
-- add new node on the replicaset
rs.add("m103.mongodb.university:27012")
-- execute
rs.isMater()
-- derrube o primary and create a new election.
rs.stepDown()

---- Configurations
- The configuration file for the first node (node1.conf):
storage:
  dbPath: /var/mongodb/db/node1
net:
  bindIp: 192.168.103.100,localhost
  port: 27011
security:
  authorization: enabled
  keyFile: /var/mongodb/pki/m103-keyfile
systemLog:
  destination: file
  path: /var/mongodb/db/node1/mongod.log
  logAppend: true
processManagement:
  fork: true
replication:
  replSetName: m103-example

 -- Creating the keyfile and setting permissions on it:
sudo mkdir -p /var/mongodb/pki/
sudo chown vagrant:vagrant /var/mongodb/pki/
openssl rand -base64 741 > /var/mongodb/pki/m103-keyfile
chmod 400 /var/mongodb/pki/m103-keyfile
 
-- Creating the dbpath for node1:
mkdir -p /var/mongodb/db/node1

-- Starting a mongod with node1.conf:
mongod -f node1.conf

-- Copying node1.conf to node2.conf and node3.conf:
cp node1.conf node2.conf
cp node2.conf node3.conf

-- Editing node2.conf using vi:
vi node2.conf

-- node2.conf, after changing the dbpath, port, and logpath:
storage:
  dbPath: /var/mongodb/db/node2
net:
  bindIp: 192.168.103.100,localhost
  port: 27012
security:
  keyFile: /var/mongodb/pki/m103-keyfile
systemLog:
  destination: file
  path: /var/mongodb/db/node2/mongod.log
  logAppend: true
processManagement:
  fork: true
replication:
  replSetName: m103-example

-- node3.conf, after changing the dbpath, port, and logpath:
storage:
  dbPath: /var/mongodb/db/node3
net:
  bindIp: 192.168.103.100,localhost
  port: 27013
security:
  keyFile: /var/mongodb/pki/m103-keyfile
systemLog:
  destination: file
  path: /var/mongodb/db/node3/mongod.log
  logAppend: true
processManagement:
  fork: true
replication:
  replSetName: m103-example

-- Creating the data directories for node2 and node3:
mkdir /var/mongodb/db/{node2,node3}

-- Starting mongod processes with node2.conf and node3.conf:
mongod -f node2.conf
mongod -f node3.conf

-- Connecting to node1:
mongo --port 27011

-- Initiating the replica set to set primary:
rs.initiate()

-- Creating a user:
use admin
db.createUser({
  user: "m103-admin",
  pwd: "m103-pass",
  roles: [
    {role: "root", db: "admin"}
  ]
})

-- Exiting out of the Mongo shell and connecting to the entire replica set:
exit
mongo --host "m103-example/192.168.103.100:27011" -u "m103-admin" -p "m103-pass" --authenticationDatabase "admin"

-- Getting replica set status:
rs.status()

-- Adding other members to replica set:
rs.add("m103:27012")
rs.add("m103:27013")

-- Getting an overview of the replica set topology:
rs.isMaster()

-- Stepping down the current primary:
rs.stepDown()

-- Checking replica set overview after election:
rs.isMaster()

- Question
Which of the following is/are true about setting up a replica set?
When connecting to a replica set, the mongo shell will redirect the connection to the primary node.
Enabling internal authentication in a replica set implicitly enables client authentication.

-- replication
- Replication Config Document is use define out Replica Set.
- members field determines the topology and roles of the individual nodes.
- Basic set of configuration options

- Replication Commands
- rs.status
-- Reports health on replica set nodes
-- Uses data from heartbeats

- rs.isMaster()
-- Descrives a node's role in the replica set.

- db.serverStatus()['repl']
-- Section of the db.serverStatus() output
-- Similar to the output of rs.isMaster() 

- rs.printReplicationInfo()
-- Only returns oplog data relative to current node.
-- Contains timestamps for first and last oplog events.

- Local DB: Part 1
-- Make a data directory and launch a mongod process for a standalone node:
mkdir allbymyselfdb
mongod --dbpath allbymyselfdb

-- Display all databases (by default, only admin and local):
mongo
show dbs

-- Display collections from the local database (this displays more collections from a replica set than from a standalone node):
use local
show collections

-- Query the oplog after connected to a replica set:
use local
db.oplog.rs.find()

-- Store oplog stats as a variable called stats:
var stats = db.oplog.rs.stats()

-- Verify that this collection is capped (it will grow to a pre-configured size before it starts to overwrite the oldest entries with newer ones):
stats.capped

-- Get current size of the oplog:
stats.size

-- Get size limit of the oplog:
stats.maxSize

-- Get current oplog data (including first and last event times, and configured oplog size):
rs.printReplicationInfo()

- Reconfiguring a Running Replica Set
-- Note: In the video lecture, we used the old hostname "m103.mongodb.university" which has been changed to "m103" . We have updated all of the following commands accordingly.
-- node4.conf:
storage:
  dbPath: /var/mongodb/db/node4
net:
  bindIp: 192.168.103.100,localhost
  port: 27014
systemLog:
  destination: file
  path: /var/mongodb/db/node4/mongod.log
  logAppend: true
processManagement:
  fork: true
replication:
  replSetName: m103-example

--  arbiter.conf:
storage:
  dbPath: /var/mongodb/db/arbiter
net:
  bindIp: 192.168.103.100,localhost
  port: 28000
systemLog:
  destination: file
  path: /var/mongodb/db/arbiter/mongod.log
  logAppend: true
processManagement:
  fork: true
replication:
  replSetName: m103-example

-- Starting up mongod processes for our fourth node and arbiter:
mongod -f node4.conf
mongod -f arbiter.confx

-- From the Mongo shell of the replica set, adding the new secondary and the new arbiter:
rs.add("m103:27014")
rs.addArb("m103:28000")

-- Checking replica set makeup after adding two new nodes:
rs.isMaster()

-- Removing the arbiter from our replica set:
rs.remove("m103:28000")

-- Assigning the current configuration to a shell variable we can edit, in order to reconfigure the replica set:
cfg = rs.conf()

-- Editing our new variable cfg to change topology - specifically, by modifying cfg.members:
cfg.members[3].votes = 0
cfg.members[3].hidden = true
cfg.members[3].priority = 0

-- Updating our replica set to use the new configuration cfg:
rs.reconfig(cfg)

mongo admin --host localhost:27001 -u m103-admin -p m103-pass

var x = rs.config();
print(x.members[2].host)
x.members[3].hidden=true
x.members[3].votes=0
x.members[3].priority=0
rs.reconfig(x);

- Reads and Writes on a Replica Set

Note: In the video lecture, we used the old hostname "m103.mongodb.university" which has been changed to "m103" . We have updated all of the following commands accordingly.

-- Connecting to the replica set:
mongo --host "m103-example/m103:27011" -u "m103-admin" -p
"m103-pass" --authenticationDatabase "admin"

- Checking replica set topology:
rs.isMaster()

- Inserting one document into a new collection:
use newDB
db.new_collection.insert( { "student": "Matt Javaly", "grade": "A+" } )

- Connecting directly to a secondary node (this node may not be a secondary in your replica set!):
mongo --host "m103:27012" -u "m103-admin" -p "m103-pass"
--authenticationDatabase "admin"

- Enabling read commands on a secondary node:
rs.slaveOk()

- Shutting down the server (on both secondary nodes)
mongo --host "m103:27011" -u "m103-admin" -p "m103-pass"
--authenticationDatabase "admin"

- Verifying that the last node stepped down to become a secondary when a majority of nodes in the set were not available:
rs.isMaster()

-- Failover and Elections

- Forcing an election in this replica set (although in this case, we rigged the election so only one node could become primary):
rs.stepDown()

-- Write Concerns: Part 1
0 - Don't wait for acknowledgement
1 (default) - Wait for acknowledgement from the primary only
>= 2 - Wait for acknowledgement from the primary and more secondaries
"majority" - Wait for acknowledgement from a majority of replica set members.

wtimeout : < int > - the time to wait for the requestes write concern before marking the operation as failed.
j (journal): <true|false> - requires the node to commit the weite operation to the journal before returning an acknowledgement.

- Recap 
Write Concern is a system of acknowledgement that provides a level of duraility guarantee.
The trade off higher write cncern levels is the speed ar which writes are committed.
MongoDB supports write concern for all cluster types: standalone, replica set, and sharded cluster.

-- Read Concerns

- Recap

-- Read concertn options: local/available, majority, and linearizable
-- Use with write concertn for  best durability guarantees

- Read Preferences
-- Read Preference Modes
Primary (Default)
primaryPreferred (primary If possible)
secondary
secondaryPrederred (primary If possible)
nearest (geographically local reads)

-- Recap
- Read Preference lets you route read opperations to specific replica set members.
- Every read preference other than primary can return stale reads.
- nearest supports geographically local reads.


-- What is Sharding?

- If you'd like to deploy a sharded cluster on your machine, you can find the commands from the lecture here:
- Configuration file for first config server csrs_1.conf:
sharding:
  clusterRole: configsvr
replication:
  replSetName: m103-csrs
security:
  keyFile: /var/mongodb/pki/m103-keyfile
net:
  bindIp: localhost,192.168.103.100
  port: 26001
systemLog:
  destination: file
  path: /var/mongodb/db/csrs1.log
  logAppend: true
processManagement:
  fork: true
storage:
  dbPath: /var/mongodb/db/csrs1
 
 - csrs_2.conf:
sharding:
  clusterRole: configsvr
replication:
  replSetName: m103-csrs
security:
  keyFile: /var/mongodb/pki/m103-keyfile
net:
  bindIp: localhost,192.168.103.100
  port: 26002
systemLog:
  destination: file
  path: /var/mongodb/db/csrs2.log
  logAppend: true
processManagement:
  fork: true
storage:
  dbPath: /var/mongodb/db/csrs2

- csrs_3.conf:
sharding:
  clusterRole: configsvr
replication:
  replSetName: m103-csrs
security:
  keyFile: /var/mongodb/pki/m103-keyfile
net:
  bindIp: localhost,192.168.103.100
  port: 26003
systemLog:
  destination: file
  path: /var/mongodb/db/csrs3.log
  logAppend: true
processManagement:
  fork: true
storage:
  dbPath: /var/mongodb/db/csrs3

- Starting the three config servers:
mongod -f csrs_1.conf
mongod -f csrs_2.conf
mongod -f csrs_3.conf

- Connect to one of the config servers:
mongo --port 26001

- Initiating the CSRS:
rs.initiate()

-Creating super user on CSRS:
use admin
db.createUser({
  user: "m103-admin",
  pwd: "m103-pass",
  roles: [
    {role: "root", db: "admin"}
  ]
})

-Authenticating as the super user:
db.auth("m103-admin", "m103-pass")

- Add the second and third node to the CSRS:
rs.add("192.168.103.100:26002")
rs.add("192.168.103.100:26003")

- Mongos config (mongos.conf):
sharding:
  configDB: m103-csrs/192.168.103.100:26001,192.168.103.100:26002,192.168.103.100:26003
security:
  keyFile: /var/mongodb/pki/m103-keyfile
net:
  bindIp: localhost,192.168.103.100
  port: 26000
systemLog:
  destination: file
  path: /var/mongodb/db/mongos.log
  logAppend: true
processManagement:
  fork: true

- Start the mongos server:
mongos -f mongos.conf

- Connect to mongos:
vagrant@m103:~$ mongo --port 26000 --username m103-admin --password m103-pass --authenticationDatabase admin

- Check sharding status:
MongoDB Enterprise mongos> sh.status()

- Updated configuration for node1.conf:
sharding:
  clusterRole: shardsvr
storage:
  dbPath: /var/mongodb/db/node1
  wiredTiger:
    engineConfig:
      cacheSizeGB: .1
net:
  bindIp: 192.168.103.100,localhost
  port: 27011
security:
  keyFile: /var/mongodb/pki/m103-keyfile
systemLog:
  destination: file
  path: /var/mongodb/db/node1/mongod.log
  logAppend: true
processManagement:
  fork: true
replication:
  replSetName: m103-repl

- Updated configuration for node2.conf:
sharding:
  clusterRole: shardsvr
storage:
  dbPath: /var/mongodb/db/node2
  wiredTiger:
    engineConfig:
      cacheSizeGB: .1
net:
  bindIp: 192.168.103.100,localhost
  port: 27012
security:
  keyFile: /var/mongodb/pki/m103-keyfile
systemLog:
  destination: file
  path: /var/mongodb/db/node2/mongod.log
  logAppend: true
processManagement:
  fork: true
replication:
  replSetName: m103-repl

- Updated configuration for node3.conf:
sharding:
  clusterRole: shardsvr
storage:
  dbPath: /var/mongodb/db/node3
  wiredTiger:
    engineConfig:
      cacheSizeGB: .1
net:
  bindIp: 192.168.103.100,localhost
  port: 27013
security:
  keyFile: /var/mongodb/pki/m103-keyfile
systemLog:
  destination: file
  path: /var/mongodb/db/node3/mongod.log
  logAppend: true
processManagement:
  fork: true
replication:
  replSetName: m103-repl

- Connecting directly to secondary node (note that if an election has taken place in your replica set, the specified node may have become primary):
mongo --port 27012 -u "m103-admin" -p "m103-pass" --authenticationDatabase "admin"

- Shutting down node:
use admin
db.shutdownServer()

- Restarting node with new configuration:
mongod -f node2.conf

- Stepping down current primary:
rs.stepDown()

- Adding new shard to cluster from mongos:
sh.addShard("m103-repl/192.168.103.100:27012")

mongo --port 26000 --username m103-admin --password m103-pass --authenticationDatabase admin


sh.addShard("shard1/localhost:27001")
sh.addShard("shard1/localhost:27002")
sh.addShard("shard1/localhost:27003")


-- Config DB

Lecture Instructions

If you'd like to explore the collections on the config database, you can find the instructions here:

Switch to config DB:
use config

Query config.databases:
db.databases.find().pretty()

Query config.collections:
db.collections.find().pretty()
 
Query config.shards:
db.shards.find().pretty()
 
Query config.chunks:
db.chunks.find().pretty()
 
Query config.mongos:
db.mongos.find().pretty()

-- Shard Keys
Shard key fields must exist in every document in the collection.
Shard key fields must be indexed
- Indexes must exist first before you can select the indexed fields for your shard key.
Shard Keys are immutable
- You cannot change the shard key fields pst-sharding
- You cannot change the values of the shard key fields post-sharding
Shard Keys are permanent.
- You cannt unshard a sharded collection

Lecture Instructions

If you'd like to shard a collection, you can find instructions to create a shard key here:

Show collections in m103 database:
use m103
show collections

Enable sharding on the m103 database:
sh.enableSharding("m103")
 
Find one document from the products collection, to help us choose a shard key:
db.products.findOne()
 
Create an index on sku:
db.products.createIndex( { "sku": 1 } )
 
Shard the products collection on sku:
sh.shardCollection( "m103.products", { "sku": 1 } )
 
Checking the status of the sharded cluster:
sh.status()

- Picking a Good Shard Key
What makes a Good Shard Key?
-- The goal is a shard key whse values provides good write distribution.
- Cardinality
  - High Cardinality = many possible unique shard key values.
- Frequency
  - 
- Monotonic Change

-- The goal is a shard key whose values prvides good write distribution
- High Cardinality - lots oof unique pssible values
- Low Frequency - very little repetitin of those unique values
- Non-Monotonically changing - non-linear change in values.

-- Sharding is a permanent operation
- You cannot unshard a collection once sharded
- You cannot update the shard key of a sharded collection.
- You cannot update the values of the shard key for any document in the sharded collection
- Test your shard keus in a staging environment first before sharding in production environments.

-- Recap
- Good shard keys provide event write distribution.
- Where possible, good shard keys prvide read isolation
- High Cardinality, Low Frequency shard key values ideal
- Avoid mnitonically changing shard keys.
- Unsharding a collection is hard - avoid it.

-- Hashed Shard Keys
Queries on ranges of shard key values are more likely to be scatter-gather.
Cannot support geographically isolated read operations using zoned sharding.
Hashed Index must be on a single non-array field.
Hashed Indexes don't support fast sorting.

- Recap
Event distribution of shard keys n monotonically changing fields like dates.
No fast sorts, targeted queries on ranges of shard key values, or geographically isolated workloads.
Hashed indexes are single field, non-array.


mongo --port 26000 --username m103-admin --password m103-pass --authenticationDatabase admin

sh.status()
mongoimport --port 26000 --username m103-admin --password m103-pass --authenticationDatabase admin --db=m103 --collection=products /dataset/products.json
sh.addShard("m103/localhost:27001")

sh.enableSharding("m103")
sh.shardCollection( "m103.products", { "sku": 1 } )
db.products.createIndex({"sky": 1})

-- Chunks
ChunkSize = 64MB - default
Shard Key Valurs Frequency
Jumbo Chunks
- Larger than the defined chunck size
- Cannot move jumbo chuncks
-- Once marked as jumbo the balancer skips these chunks and avoids trying to move them.
- In some cases these will not be able to be split.

-- Recap
Logical groups of documents.
Chunk can only live at one designated shard at a time
Shard key cardinality/frequency, chunk size will determine number of chunks.

Which of the following is true about chunks?
Chunk ranges have an inclusive minimum and an exclusive maximum.


Lecture Instructions

Show collections in config database:

use config
show collections

Find one document from the chunks collection:
db.chunks.findOne()
 
Change the chunk size:
use config
db.settings.save({_id: "chunksize", value: 2})
 
Check the status of the sharded cluster:
sh.status()
 
Import the new products.part2 dataset into MongoDB:
mongoimport /dataset/products.part2.json --port 26000 -u "m103-admin" -p "m103-pass" --authenticationDatabase "admin" --db m103 --collection products

-- Balancing

Balancer Management methods
- Start/Stop balancer
-- sh.startBalancer(timeout, interval)
-- sh.stopBalancer(timeout, interval)
-- sh.setBalancerState(boolean)

-- Recap 
Balancer responsible for evenly distributing chuncks across the sharded cluster
Balancer runs on Primary member of config server replica set
Balancer is an automatic process and requires minimal user configuration

- Lecture Instructions

Start the balancer:
sh.startBalancer(timeout, interval)

Stop the balancer:
sh.stopBalancer(timeout, interval)
 
Enable/disable the balancer:
sh.setBalancerState(boolean)

--- Queries in a Sharded Cluster

Sort, Limit, and Skip in sharded clusters
- sort() - the mongos pushes the sort to each shard and merge-ssrts the results.
- limit() - thr mongs passes the limit to each targeted sshard, than, re-applies the limit to the merged set of results.

- When used in conjunction with a limit(), the mongos will pass the limit plus the value of the skip() to the shards to ensure a sufficient number of documents are returned to the mongos to apply the final limit() and skip() successfully.

- Recap
Mongos handles all queries in the cluster
Mongos builds a list of shards to target a query
Mongos merges the results from each shard
Mongos supports standard query modifiers like sort, limit, and skip.

For a find() operation, which cluster component is responsible for merging the query results?
The mongos that issued the query

-- Targeted Queries vs Scatter Gather

- Recap
Targeted queries required the shard key in the Query
Ranged queries n the shard key may still require targeting every shard in the cluster
Without the shard key, the mongos musst perform a scatter-gather query.

-- Lecture Instructions

Show collections in the m103 database:
use m103
show collections
 
Targeted query with explain() output:
db.products.find({"sku" : 1000000749 }).explain()
 
Scatter gather query with explain() output:
db.products.find( {
  "name" : "Gods And Heroes: Rome Rising - Windows [Digital Download]" }
).explain()
 

















